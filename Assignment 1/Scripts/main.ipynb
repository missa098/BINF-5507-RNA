# 1. Import necessary modules
import data_preprocessor as dp
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


# 2. Load the dataset
messy_data = pd.read_csv('../Data/messy_data.csv')
clean_data = messy_data.copy()

# 3. Examine the Dataset
#check the structure 
messy_data.head()

#check data types, missing values, and basic statistics
messy_data.info()
messy_data.describe()


# 4. Preprocess the data
clean_data = dp.impute_missing_values(clean_data, strategy='mean')
clean_data = dp.remove_duplicates(clean_data)
clean_data = dp.normalize_data(clean_data)
clean_data = dp.remove_redundant_features(clean_data)


# 4. a look for outliers 
# Plot histograms for all numeric features
clean_data.hist(figsize=(12, 8), bins=30, edgecolor='black')
plt.suptitle("Feature Distributions", fontsize=14)
plt.show()

# Boxplot for all numeric features
plt.figure(figsize=(12, 6))
sns.boxplot(data=clean_data)
plt.xticks(rotation=45)
plt.title("Boxplot of Numeric Features (Detecting Outliers)")
plt.show()

#5. Save the cleaned dataset
clean_data.to_csv('../Data/clean_data.csv', index=False)

# 6. Train and evaluate the model
#This step was added due to initial ValueError. I had to convert the continuous target variable into discrete classes.
median_value = clean_data['target'].median()
clean_data['target'] = np.where(clean_data['target'] > median_value, 1, 0)

dp.simple_model(clean_data) #had to add dp. infront of simple model 
